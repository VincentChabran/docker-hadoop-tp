{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "# from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, MinMaxScaler\n",
    "# from pyspark.ml.clustering import KMeans\n",
    "# from pyspark.sql import functions as F\n",
    "# import sys\n",
    "# from pyspark.sql import SparkSession\n",
    "# import matplotlib.pyplot as plt\n",
    "# from pyspark.sql import functions as F\n",
    "# import seaborn as sns\n",
    "# from pyspark.sql.types import StructType, StructField, StringType, FloatType, IntegerType, BooleanType"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T17:17:40.268053900Z",
     "start_time": "2024-11-20T17:17:40.251521400Z"
    }
   },
   "id": "337c358ee36c9019"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "# spark = SparkSession.builder \\\n",
    "#     .appName(\"Data Processing dans catalogue csv\") \\\n",
    "#     .config(\"spark.hadoop.hive.metastore.uris\", \"thrift://hive-metastore:9083\") \\\n",
    "#     .enableHiveSupport() \\\n",
    "#     .getOrCreate()\n",
    "# print(\"Session Spark initialisée avec succès.\")\n",
    "# spark.sql(\"USE concessionnaire\")\n",
    "# catalogue_df = spark.sql(\"SELECT * FROM catalogue_co2_merge_processed\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T17:17:40.275651200Z",
     "start_time": "2024-11-20T17:17:40.256418800Z"
    }
   },
   "id": "5675739878b8a856"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "# catalogue_df.show(10)\n",
    "# catalogue_df.printSchema()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T17:17:40.280491400Z",
     "start_time": "2024-11-20T17:17:40.261715500Z"
    }
   },
   "id": "eaa41c7f1a0ddbf1"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-20T17:17:40.292478200Z",
     "start_time": "2024-11-20T17:17:40.270311300Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Liste des colonnes catégorielles et numériques\n",
    "# categorical_cols = ['marque', 'modele', 'couleur', 'longueur']\n",
    "# numerical_cols = ['prix', 'unified_horse_power', 'rejets_co2', 'bonus_malus', 'nbplaces', 'nbportes']\n",
    "# \n",
    "# # Étape 1 : Encodage des colonnes catégorielles\n",
    "# indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_index\") for col in categorical_cols]\n",
    "# for indexer in indexers:\n",
    "#     catalogue_df = indexer.fit(catalogue_df).transform(catalogue_df)\n",
    "# \n",
    "# # Vérifier les colonnes encodées\n",
    "# encoded_cols = [f\"{col}_index\" for col in categorical_cols]\n",
    "# \n",
    "# # Étape 2 : Préparer les colonnes numériques\n",
    "# # Convertir toutes les colonnes numériques en double\n",
    "# numerical_cols_full = numerical_cols + encoded_cols\n",
    "# catalogue_df = catalogue_df.select(\n",
    "#     *[F.col(c).cast('double').alias(c) for c in numerical_cols_full],\n",
    "#     *[F.col(c) for c in ['marque', 'modele']]\n",
    "# )\n",
    "# \n",
    "# # Remplir les valeurs NULL par des valeurs par défaut\n",
    "# catalogue_df = catalogue_df.fillna({col: 0 for col in numerical_cols_full})\n",
    "# \n",
    "# # Étape 3 : Création du vecteur d'entrée\n",
    "# assembler = VectorAssembler(inputCols=numerical_cols_full, outputCol='features_raw')\n",
    "# assembled_df = assembler.transform(catalogue_df)\n",
    "# \n",
    "# # Étape 4 : Normalisation des données\n",
    "# scaler = MinMaxScaler(inputCol='features_raw', outputCol='features')\n",
    "# scaled_model = scaler.fit(assembled_df)\n",
    "# scaled_df = scaled_model.transform(assembled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "# # Étape 5 : Appliquer K-Means\n",
    "# kmeans = KMeans(featuresCol='features', k=10, seed=1)  # k=5 comme point de départ\n",
    "# model = kmeans.fit(scaled_df)\n",
    "# \n",
    "# # Obtenir les prédictions de clusters\n",
    "# clustered_df = model.transform(scaled_df)\n",
    "# \n",
    "# # Résumé des clusters\n",
    "# cluster_summary = clustered_df.groupBy('prediction').agg(\n",
    "#     F.count('*').alias('count'),\n",
    "#     *[F.mean(col).alias(f\"avg_{col}\") for col in numerical_cols]\n",
    "# )\n",
    "# cluster_summary.show()\n",
    "# \n",
    "# # Ajouter les catégories en fonction des clusters\n",
    "# def assign_category(prediction):\n",
    "#     if prediction == 1:\n",
    "#         return 'Citadines/compactes'\n",
    "#     elif prediction == 2:\n",
    "#         return 'Routières premium'\n",
    "#     elif prediction == 4:\n",
    "#         return 'Sportives premium'\n",
    "#     else:\n",
    "#         return 'Autres'\n",
    "# \n",
    "# assign_category_udf = F.udf(assign_category, StringType())\n",
    "# clustered_df = clustered_df.withColumn(\"categorie\", assign_category_udf(F.col(\"prediction\")))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T17:17:40.293543Z",
     "start_time": "2024-11-20T17:17:40.274046900Z"
    }
   },
   "id": "1296cad4f82bff38"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# # Résumé des clusters\n",
    "# cluster_summary = clustered_df.groupBy('prediction').agg(\n",
    "#     F.count('*').alias('count'),\n",
    "#     *[F.mean(col).alias(f\"avg_{col}\") for col in numerical_cols]\n",
    "# )\n",
    "# cluster_summary.show()\n",
    "# \n",
    "# # Définir les catégories des clusters\n",
    "# def assign_category(prediction):\n",
    "#     if prediction == 1:\n",
    "#         return 'Citadines/compactes'\n",
    "#     elif prediction == 2:\n",
    "#         return 'Routières premium'\n",
    "#     elif prediction == 3:\n",
    "#         return 'SUV'\n",
    "#     elif prediction == 4:\n",
    "#         return 'Sportives premium'\n",
    "#     elif prediction == 5:\n",
    "#         return 'Économiques'\n",
    "#     else:\n",
    "#         return 'Autres'\n",
    "# \n",
    "# assign_category_udf = F.udf(assign_category, StringType())\n",
    "# clustered_df = clustered_df.withColumn(\"categorie\", assign_category_udf(F.col(\"prediction\")))\n",
    "# \n",
    "# # Afficher les données avec les catégories\n",
    "# clustered_df.select('prediction', 'categorie', 'marque', 'modele', *numerical_cols).show(truncate=False)\n",
    "# \n",
    "# # Réduction de dimensions avec PCA\n",
    "# # Réduction de dimensions avec PCA\n",
    "# pca = PCA(k=2, inputCol='features', outputCol='pca_features')\n",
    "# pca_model = pca.fit(scaled_df)\n",
    "# pca_result = pca_model.transform(clustered_df)  # Utilisez clustered_df, qui contient 'prediction'\n",
    "# \n",
    "# # Convertir les résultats en Pandas pour visualisation\n",
    "# pandas_df = pca_result.select('pca_features', 'prediction', 'marque', 'modele', 'categorie').toPandas()\n",
    "# \n",
    "# # Séparer les composants PCA\n",
    "# # Séparer les composants PCA\n",
    "# pandas_df[['pca_x', 'pca_y']] = pandas_df['pca_features'].apply(lambda x: [x[0], x[1]]).to_list()\n",
    "# \n",
    "# \n",
    "# # Visualisation des clusters\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.scatterplot(\n",
    "#     data=pandas_df,\n",
    "#     x='pca_x',\n",
    "#     y='pca_y',\n",
    "#     hue='categorie',\n",
    "#     style='categorie',\n",
    "#     palette='Set2',\n",
    "#     s=100,\n",
    "#     alpha=0.8\n",
    "# )\n",
    "# plt.title(\"Visualisation des Clusters avec PCA\", fontsize=16)\n",
    "# plt.xlabel(\"PCA Component 1\", fontsize=12)\n",
    "# plt.ylabel(\"PCA Component 2\", fontsize=12)\n",
    "# plt.legend(title=\"Catégories\", fontsize=10, title_fontsize=12)\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "# \n",
    "# \n",
    "# from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "# \n",
    "# # Tester différents nombres de clusters\n",
    "# for k in range(3, 12):  # Par exemple, tester entre 3 et 7 clusters\n",
    "#     kmeans = KMeans(featuresCol='features', k=k, seed=1)\n",
    "#     model = kmeans.fit(scaled_df)\n",
    "#     predictions = model.transform(scaled_df)\n",
    "#     \n",
    "#     # Évaluer les clusters avec le score silhouette\n",
    "#     evaluator = ClusteringEvaluator(featuresCol='features')\n",
    "#     silhouette = evaluator.evaluate(predictions)\n",
    "#     print(f\"Pour k={k}, score silhouette={silhouette}\")\n",
    "# \n",
    "# # Récupérer les centroïdes des clusters\n",
    "# centroids = model.clusterCenters()\n",
    "# \n",
    "# # Ajouter les centroïdes au graphique\n",
    "# centroids_pca = pca_model.transform(\n",
    "#     spark.createDataFrame(centroids, schema=[\"features\"])\n",
    "# ).toPandas()\n",
    "# \n",
    "# centroids_pca[['pca_x', 'pca_y']] = centroids_pca['pca_features'].apply(lambda x: [x[0], x[1]]).to_list()\n",
    "# \n",
    "# # Tracer les clusters et les centroïdes\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.scatterplot(\n",
    "#     data=pandas_df,\n",
    "#     x='pca_x',\n",
    "#     y='pca_y',\n",
    "#     hue='categorie',\n",
    "#     style='categorie',\n",
    "#     palette='Set2',\n",
    "#     s=100,\n",
    "#     alpha=0.8\n",
    "# )\n",
    "# \n",
    "# # Ajouter les centroïdes\n",
    "# plt.scatter(\n",
    "#     centroids_pca['pca_x'], \n",
    "#     centroids_pca['pca_y'], \n",
    "#     s=300, c='red', marker='X', label='Centroïdes'\n",
    "# )\n",
    "# \n",
    "# plt.title(\"Visualisation des Clusters avec PCA\", fontsize=16)\n",
    "# plt.xlabel(\"PCA Component 1\", fontsize=12)\n",
    "# plt.ylabel(\"PCA Component 2\", fontsize=12)\n",
    "# plt.legend(title=\"Catégories\", fontsize=10, title_fontsize=12)\n",
    "# plt.grid(True)\n",
    "# plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T17:17:40.293543Z",
     "start_time": "2024-11-20T17:17:40.281019800Z"
    }
   },
   "id": "7e296432db8731ed"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session Spark initialisée avec succès.\n",
      "+-------+---------+-----------------+-------------------+\n",
      "| marque|   modele|       rejets_co2|unified_horse_power|\n",
      "+-------+---------+-----------------+-------------------+\n",
      "|renault|   laguna|75.96444444444448|              170.0|\n",
      "|renault|   megane|75.96444444444448|              135.0|\n",
      "|renault|   laguna|75.96444444444448|              170.0|\n",
      "|renault|   megane|75.96444444444448|              135.0|\n",
      "|renault|   megane|75.96444444444448|              135.0|\n",
      "|renault|   megane|75.96444444444448|              135.0|\n",
      "|renault|   megane|75.96444444444448|              135.0|\n",
      "|renault|   espace|75.96444444444448|              165.0|\n",
      "|renault|vel satis|75.96444444444448|              245.0|\n",
      "|renault|vel satis|75.96444444444448|              245.0|\n",
      "|renault|   laguna|75.96444444444448|              170.0|\n",
      "|renault|   megane|75.96444444444448|              135.0|\n",
      "|renault|   laguna|75.96444444444448|              170.0|\n",
      "|renault|   espace|75.96444444444448|              165.0|\n",
      "|renault|   espace|75.96444444444448|              165.0|\n",
      "|renault|vel satis|75.96444444444448|              245.0|\n",
      "|renault|   espace|75.96444444444448|              165.0|\n",
      "|renault|   megane|75.96444444444448|              135.0|\n",
      "|renault|vel satis|75.96444444444448|              245.0|\n",
      "|renault|   laguna|75.96444444444448|              170.0|\n",
      "+-------+---------+-----------------+-------------------+\n",
      "only showing top 20 rows\n",
      "+----------+-----+------------------+------------------+------------------+------------------+-------------+-------------+\n",
      "|prediction|count|mean_prix         |mean_horse_power  |mean_rejets_co2   |mean_bonus_malus  |mean_nbplaces|mean_nbportes|\n",
      "+----------+-----+------------------+------------------+------------------+------------------+-------------+-------------+\n",
      "|0         |10   |42925.0           |272.0             |42.100000000000016|0.0               |5.0          |5.0          |\n",
      "|1         |10   |86105.0           |306.0             |171.20000000000002|7772.1            |5.0          |5.0          |\n",
      "|2         |10   |80580.0           |507.0             |38.699999999999996|-6000.0           |5.0          |5.0          |\n",
      "|3         |25   |10508.0           |69.6              |78.22             |-867.18           |5.0          |3.0          |\n",
      "|4         |20   |24518.25          |157.5             |44.632222222222225|-6000.0           |7.0          |5.0          |\n",
      "|5         |65   |21837.384615384617|133.23076923076923|138.03076923076924|4106.846153846152 |5.0          |5.0          |\n",
      "|6         |45   |15522.555555555555|90.55555555555556 |17.766666666666673|-6000.0           |5.0          |5.0          |\n",
      "|7         |80   |27683.3125        |173.75            |56.69472222222221 |-6000.0           |5.0          |5.0          |\n",
      "|8         |10   |17755.0           |114.0             |121.5             |2554.7000000000003|7.0          |5.0          |\n",
      "+----------+-----+------------------+------------------+------------------+------------------+-------------+-------------+\n",
      "\n",
      "Exemples pour la catégorie : Micro-citadines électriques\n",
      "+-------+-------+-------+-------------------+----------+--------+--------+\n",
      "|marque |modele |prix   |unified_horse_power|rejets_co2|nbplaces|nbportes|\n",
      "+-------+-------+-------+-------------------+----------+--------+--------+\n",
      "|kia    |picanto|8990.0 |65.0               |15.5      |5.0     |5.0     |\n",
      "|peugeot|1007   |9625.0 |75.0               |12.8      |5.0     |5.0     |\n",
      "|peugeot|1007   |13750.0|75.0               |12.8      |5.0     |5.0     |\n",
      "|audi   |a2     |18310.0|75.0               |24.6      |5.0     |5.0     |\n",
      "|audi   |a2     |12817.0|75.0               |24.6      |5.0     |5.0     |\n",
      "+-------+-------+-------+-------------------+----------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Exemples pour la catégorie : Berlines intermédiaires thermiques\n",
      "+--------+------+-------+-------------------+----------+--------+--------+\n",
      "|marque  |modele|prix   |unified_horse_power|rejets_co2|nbplaces|nbportes|\n",
      "+--------+------+-------+-------------------+----------+--------+--------+\n",
      "|mercedes|a200  |18130.0|136.0              |171.2     |5.0     |5.0     |\n",
      "|mercedes|a200  |18130.0|136.0              |171.2     |5.0     |5.0     |\n",
      "|mercedes|a200  |25900.0|136.0              |171.2     |5.0     |5.0     |\n",
      "|mercedes|a200  |18130.0|136.0              |171.2     |5.0     |5.0     |\n",
      "|nissan  |maxima|30000.0|200.0              |160.0     |5.0     |5.0     |\n",
      "+--------+------+-------+-------------------+----------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Exemples pour la catégorie : Citadines économiques\n",
      "+----------+------+-------+-------------------+----------+--------+--------+\n",
      "|marque    |modele|prix   |unified_horse_power|rejets_co2|nbplaces|nbportes|\n",
      "+----------+------+-------+-------------------+----------+--------+--------+\n",
      "|volkswagen|polo  |12200.0|55.0               |13.3      |5.0     |3.0     |\n",
      "|volkswagen|polo  |8540.0 |55.0               |13.3      |5.0     |3.0     |\n",
      "|volkswagen|polo  |12200.0|55.0               |13.3      |5.0     |3.0     |\n",
      "|volkswagen|polo  |8540.0 |55.0               |13.3      |5.0     |3.0     |\n",
      "|volkswagen|polo  |8540.0 |55.0               |13.3      |5.0     |3.0     |\n",
      "+----------+------+-------+-------------------+----------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Exemples pour la catégorie : Berlines de luxe\n",
      "+--------+------+--------+-------------------+----------+--------+--------+\n",
      "|marque  |modele|prix    |unified_horse_power|rejets_co2|nbplaces|nbportes|\n",
      "+--------+------+--------+-------------------+----------+--------+--------+\n",
      "|mercedes|s500  |70910.0 |306.0              |171.2     |5.0     |5.0     |\n",
      "|mercedes|s500  |101300.0|306.0              |171.2     |5.0     |5.0     |\n",
      "|mercedes|s500  |70910.0 |306.0              |171.2     |5.0     |5.0     |\n",
      "|mercedes|s500  |101300.0|306.0              |171.2     |5.0     |5.0     |\n",
      "|mercedes|s500  |101300.0|306.0              |171.2     |5.0     |5.0     |\n",
      "+--------+------+--------+-------------------+----------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Exemples pour la catégorie : Citadines compactes\n",
      "+-------+------+-------+-------------------+----------+--------+--------+\n",
      "|marque |modele|prix   |unified_horse_power|rejets_co2|nbplaces|nbportes|\n",
      "+-------+------+-------+-------------------+----------+--------+--------+\n",
      "|hyundaï|matrix|15960.0|103.0              |121.5     |7.0     |5.0     |\n",
      "|honda  |fr-v  |19550.0|125.0              |121.5     |7.0     |5.0     |\n",
      "|honda  |fr-v  |19550.0|125.0              |121.5     |7.0     |5.0     |\n",
      "|hyundaï|matrix|15960.0|103.0              |121.5     |7.0     |5.0     |\n",
      "|hyundaï|matrix|15960.0|103.0              |121.5     |7.0     |5.0     |\n",
      "+-------+------+-------+-------------------+----------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Exemples pour la catégorie : Citadines\n",
      "+----------+------+-------+-------------------+------------------+--------+--------+\n",
      "|marque    |modele|prix   |unified_horse_power|rejets_co2        |nbplaces|nbportes|\n",
      "+----------+------+-------+-------------------+------------------+--------+--------+\n",
      "|renault   |laguna|19110.0|170.0              |75.96444444444448 |5.0     |5.0     |\n",
      "|renault   |megane|22350.0|135.0              |75.96444444444448 |5.0     |5.0     |\n",
      "|jaguar    |x-type|25970.0|197.0              |75.96444444444448 |5.0     |5.0     |\n",
      "|volkswagen|golf  |22900.0|150.0              |40.0              |5.0     |5.0     |\n",
      "|bmw       |120i  |35800.0|150.0              |38.699999999999996|5.0     |5.0     |\n",
      "+----------+------+-------+-------------------+------------------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Exemples pour la catégorie : Familiales grandes places\n",
      "+----------+------+-------+-------------------+-----------------+--------+--------+\n",
      "|marque    |modele|prix   |unified_horse_power|rejets_co2       |nbplaces|nbportes|\n",
      "+----------+------+-------+-------------------+-----------------+--------+--------+\n",
      "|volkswagen|touran|27340.0|150.0              |13.3             |7.0     |5.0     |\n",
      "|renault   |espace|21245.0|165.0              |75.96444444444448|7.0     |5.0     |\n",
      "|volkswagen|touran|27340.0|150.0              |13.3             |7.0     |5.0     |\n",
      "|renault   |espace|30350.0|165.0              |75.96444444444448|7.0     |5.0     |\n",
      "|renault   |espace|21245.0|165.0              |75.96444444444448|7.0     |5.0     |\n",
      "+----------+------+-------+-------------------+-----------------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Exemples pour la catégorie : Voitures sportives haut de gamme\n",
      "+------+------+-------+-------------------+------------------+--------+--------+\n",
      "|marque|modele|prix   |unified_horse_power|rejets_co2        |nbplaces|nbportes|\n",
      "+------+------+-------+-------------------+------------------+--------+--------+\n",
      "|bmw   |m5    |66360.0|507.0              |38.699999999999996|5.0     |5.0     |\n",
      "|bmw   |m5    |94800.0|507.0              |38.699999999999996|5.0     |5.0     |\n",
      "|bmw   |m5    |94800.0|507.0              |38.699999999999996|5.0     |5.0     |\n",
      "|bmw   |m5    |94800.0|507.0              |38.699999999999996|5.0     |5.0     |\n",
      "|bmw   |m5    |66360.0|507.0              |38.699999999999996|5.0     |5.0     |\n",
      "+------+------+-------+-------------------+------------------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Exemples pour la catégorie : Berlines hybrides haut de gamme\n",
      "+------+------+-------+-------------------+-----------------+--------+--------+\n",
      "|marque|modele|prix   |unified_horse_power|rejets_co2       |nbplaces|nbportes|\n",
      "+------+------+-------+-------------------+-----------------+--------+--------+\n",
      "|volvo |s80 t6|35350.0|272.0              |42.10000000000001|5.0     |5.0     |\n",
      "|volvo |s80 t6|50500.0|272.0              |42.10000000000001|5.0     |5.0     |\n",
      "|volvo |s80 t6|35350.0|272.0              |42.10000000000001|5.0     |5.0     |\n",
      "|volvo |s80 t6|35350.0|272.0              |42.10000000000001|5.0     |5.0     |\n",
      "|volvo |s80 t6|35350.0|272.0              |42.10000000000001|5.0     |5.0     |\n",
      "+------+------+-------+-------------------+-----------------+--------+--------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import when, col, lit\n",
    "from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "# Initialisation de la session Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Clustering Véhicules\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "print(\"Session Spark initialisée avec succès.\")\n",
    "spark.sql(\"USE concessionnaire\")\n",
    "\n",
    "# Charger les données\n",
    "catalogue_df = spark.sql(\"SELECT * FROM catalogue_co2_merge_processed\")\n",
    "\n",
    "# Étape 0 : Identification et correction des anomalies dans 'rejets_co2'\n",
    "\n",
    "# 1. Identification des anomalies dans 'rejets_co2'\n",
    "anomalies_df = catalogue_df.filter(\n",
    "    (col('rejets_co2').isNull()) |\n",
    "    (col('rejets_co2') == 0) |\n",
    "    ((col('unified_horse_power') > 100) & (col('rejets_co2') < 50))\n",
    ")\n",
    "\n",
    "# 2. Calcul des moyennes nécessaires pour imputer les valeurs manquantes ou aberrantes\n",
    "\n",
    "# a) Moyenne par modèle (en incluant les valeurs aberrantes pour assurer le calcul de la moyenne)\n",
    "avg_co2_by_model = catalogue_df.filter(\n",
    "    (col('rejets_co2').isNotNull()) &\n",
    "    (col('rejets_co2') > 0)\n",
    ").groupBy('marque', 'modele').agg(\n",
    "    F.avg('rejets_co2').alias('avg_rejets_co2_model')\n",
    ")\n",
    "\n",
    "# b) Moyenne par marque\n",
    "avg_co2_by_marque = catalogue_df.filter(\n",
    "    (col('rejets_co2').isNotNull()) &\n",
    "    (col('rejets_co2') > 0)\n",
    ").groupBy('marque').agg(\n",
    "    F.avg('rejets_co2').alias('avg_rejets_co2_marque')\n",
    ")\n",
    "\n",
    "# c) Moyenne générale\n",
    "avg_co2_general = catalogue_df.filter(\n",
    "    (col('rejets_co2').isNotNull()) &\n",
    "    (col('rejets_co2') > 0)\n",
    ").agg(\n",
    "    F.avg('rejets_co2').alias('avg_rejets_co2_general')\n",
    ").collect()[0]['avg_rejets_co2_general']\n",
    "\n",
    "# 3. Imputation des valeurs manquantes ou aberrantes selon les consignes\n",
    "\n",
    "# a) Joindre les moyennes au DataFrame des anomalies\n",
    "anomalies_df = anomalies_df.join(avg_co2_by_model, on=['marque', 'modele'], how='left')\n",
    "anomalies_df = anomalies_df.join(avg_co2_by_marque, on='marque', how='left')\n",
    "anomalies_df = anomalies_df.withColumn('avg_rejets_co2_general', lit(avg_co2_general))\n",
    "\n",
    "# b) Remplacer les valeurs de 'rejets_co2' selon les priorités\n",
    "anomalies_df = anomalies_df.withColumn(\n",
    "    'rejets_co2',\n",
    "    when(\n",
    "        col('avg_rejets_co2_model').isNotNull(),\n",
    "        col('avg_rejets_co2_model')\n",
    "    ).when(\n",
    "        col('avg_rejets_co2_marque').isNotNull(),\n",
    "        col('avg_rejets_co2_marque')\n",
    "    ).otherwise(\n",
    "        col('avg_rejets_co2_general')\n",
    "    )\n",
    ")\n",
    "\n",
    "# c) Supprimer les colonnes temporaires de moyennes\n",
    "anomalies_df = anomalies_df.drop('avg_rejets_co2_model', 'avg_rejets_co2_marque', 'avg_rejets_co2_general')\n",
    "\n",
    "# 4. Mettre à jour le DataFrame initial avec les valeurs corrigées\n",
    "\n",
    "# a) Exclure les anomalies du DataFrame initial\n",
    "catalogue_non_anomalies = catalogue_df.join(\n",
    "    anomalies_df.select('marque', 'modele', 'unified_horse_power', 'rejets_co2'),\n",
    "    on=['marque', 'modele', 'unified_horse_power'],\n",
    "    how='left_anti'\n",
    ")\n",
    "\n",
    "# b) Combiner les données corrigées avec le reste du DataFrame\n",
    "catalogue_corrected_df = catalogue_non_anomalies.unionByName(anomalies_df)\n",
    "\n",
    "# Vérification des corrections\n",
    "# Afficher les valeurs de 'rejets_co2' pour les modèles Renault\n",
    "catalogue_corrected_df.filter(col('marque') == 'renault').select(\n",
    "    'marque', 'modele', 'rejets_co2', 'unified_horse_power'\n",
    ").show()\n",
    "\n",
    "# Étape 1 : Préparation pour le clustering\n",
    "\n",
    "numerical_cols = ['prix', 'unified_horse_power', 'rejets_co2', 'bonus_malus', 'nbplaces', 'nbportes']\n",
    "\n",
    "clustering_df = catalogue_corrected_df.select(\n",
    "    *[col(c).cast('double').alias(c) for c in numerical_cols],\n",
    "    'marque', 'modele'\n",
    ").fillna({col: 0 for col in numerical_cols})\n",
    "\n",
    "# Assemblage des variables en un vecteur de caractéristiques\n",
    "assembler = VectorAssembler(inputCols=numerical_cols, outputCol='features_raw')\n",
    "assembled_df = assembler.transform(clustering_df)\n",
    "\n",
    "# Normalisation des données\n",
    "scaler = MinMaxScaler(inputCol='features_raw', outputCol='features')\n",
    "scaler_model = scaler.fit(assembled_df)\n",
    "scaled_df = scaler_model.transform(assembled_df)\n",
    "\n",
    "# Étape 2 : Clustering avec K-Means\n",
    "\n",
    "k = 9\n",
    "kmeans = KMeans(featuresCol='features', k=k, seed=1)\n",
    "model = kmeans.fit(scaled_df)\n",
    "clustered_df = model.transform(scaled_df)\n",
    "\n",
    "# Étape 3 : Analyse des clusters\n",
    "\n",
    "cluster_stats = clustered_df.groupBy('prediction').agg(\n",
    "    F.count('*').alias('count'),\n",
    "    F.mean('prix').alias('mean_prix'),\n",
    "    F.mean('unified_horse_power').alias('mean_horse_power'),\n",
    "    F.mean('rejets_co2').alias('mean_rejets_co2'),\n",
    "    F.mean('bonus_malus').alias('mean_bonus_malus'),\n",
    "    F.mean('nbplaces').alias('mean_nbplaces'),\n",
    "    F.mean('nbportes').alias('mean_nbportes')\n",
    ").orderBy('prediction')\n",
    "\n",
    "cluster_stats.show(truncate=False)\n",
    "\n",
    "# Étape 4 : Assignation des catégories\n",
    "\n",
    "clustered_df = clustered_df.withColumn(\n",
    "    \"categorie\",\n",
    "    when(col(\"prediction\") == 0, \"Berlines hybrides haut de gamme\") \n",
    "    .when(col(\"prediction\") == 1, \"Berlines de luxe\")\n",
    "    .when(col(\"prediction\") == 2, \"Voitures sportives haut de gamme\")\n",
    "    .when(col(\"prediction\") == 3, \"Citadines économiques\")\n",
    "    .when(col(\"prediction\") == 4, \"Familiales grandes places\")\n",
    "    .when(col(\"prediction\") == 5, \"Berlines intermédiaires thermiques\")\n",
    "    .when(col(\"prediction\") == 6, \"Micro-citadines électriques\") \n",
    "    .when(col(\"prediction\") == 7, \"Citadines\")\n",
    "    .when(col(\"prediction\") == 8, \"Citadines compactes\")\n",
    "    .otherwise(\"Autres\")\n",
    ")\n",
    "\n",
    "# Étape 5 : Vérification des catégories\n",
    "\n",
    "categories = clustered_df.select(\"categorie\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "for cat in categories:\n",
    "    print(f\"\\nExemples pour la catégorie : {cat}\")\n",
    "    clustered_df.filter(col(\"categorie\") == cat).select(\n",
    "        \"marque\", \"modele\", \"prix\", \"unified_horse_power\", \"rejets_co2\", \"nbplaces\", \"nbportes\"\n",
    "    ).show(5, truncate=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T17:17:44.317215200Z",
     "start_time": "2024-11-20T17:17:40.287137600Z"
    }
   },
   "id": "576765ac9d2156b6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
